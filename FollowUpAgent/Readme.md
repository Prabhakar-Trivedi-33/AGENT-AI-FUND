📄 Scope Document: Follow-Up Agent Implementation

📌 Objective
To design and implement a Follow-Up Agent that enhances user engagement and exploration by generating relevant follow-up questions based on the response generated by a primary agent (e.g., Portfolio Agent, Fund Agent, Tax Agent, etc.). This agent will act as a post-processor in the agent execution pipeline and will return a set of contextual follow-up questions along with the original agent response.

🧩 Scope of Work
1. Input Handling
Accepts structured responses from any primary agent (e.g., Portfolio Agent, Fund Agent, Recommendation Agent, History etc). This all should be available in Agent State


Supports optional metadata such as agent type, user intent, and user context (e.g., investment profile, past queries).


2. LLM-Based Question Generation
Use prompt templates to extract themes and generate relevant, contextual follow-up questions.


3. Classification and Filtering
Filter out redundant or irrelevant questions using relevance scoring (optional).


Limit the number of follow-up questions (configurable, e.g., 2–3 per response).


4. Structured Output
Return original agent response with an additional follow_up_questions field.


Request Structure: (Agent state)

Access data from Agent state object, it’ll have user request like query, history, data from different agents like portfolio & fund information.

Previous follow up questions will be part of history, consider that data to not repeat follow up questions.
Response Structure: (Updated Agent state)
Add new entry to agent state, follow_up_questions and update it with required follow up questions or options.

🛠 Implementation Details
Class to create: FollowUpAgent


Module: follow_up_agent.py


Prompt logic file: create new follow_up_agent_prompt.py


LLM handler: Reuse existing interface for LLM call


Branch: dev


Repository: arth-backend-fast-api - https://github.com/wealthwisedev/arth-backend-fast-api




🔄 Agent Framework Integration
Register FollowUpAgent in the agent graph as a post-processing node.


Ensure the agent can be invoked after any primary agent completes its execution and before the response is returned to the user.


Design it as a plug-and-play module for extensibility across multiple agent types.



✅ Deliverables
follow_up_agent.py with:


Agent class definition


Prompt construction and LLM integration


Output formatting logic


Output schema defined and validated


Agent registered in the agent graph and testable via pipeline


Optional: Simple keyword-based mock generator for testing without LLM



🧪 Testing & Validation
Use mock outputs from various agents (Portfolio, Fund, Tax, etc.) to validate response parsing.


Validate:


Relevance of follow-up questions


Tone and diversity of questions


Integration with overall JSON schema


Write unit tests with both LLM-enabled and mock modes



⚠️ Notes
This agent should not duplicate previous responses or questions.


Should be designed to extend naturally as more agents and response types are added.


Consider adding user profile awareness (e.g., risk level, knowledge level) for smarter follow-up generation in future phases.



